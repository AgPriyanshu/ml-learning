{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import all libs.\n",
        "import os\n",
        "import requests\n",
        "from duckduckgo_search import DDGS\n",
        "from pathlib import Path\n",
        "import time\n",
        "import dask\n",
        "\n",
        "# Constants.\n",
        "DATASET_DIR = Path(os.getcwd()) / \"datasets\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def download_images(query, output_dir,max_results=50):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    ddg = DDGS()\n",
        "    results = ddg.images(query, max_results=max_results)\n",
        "    \n",
        "    for idx, result in enumerate(results):\n",
        "        image_url = result[\"image\"]\n",
        "        try:\n",
        "            response = requests.get(image_url, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            ext = image_url.split(\".\")[-1].split(\"?\")[0][:4]\n",
        "            filename = os.path.join(output_dir, f\"{query.replace(' ', '_')}_{idx}.{ext}\")\n",
        "            with open(filename, \"wb\") as f:\n",
        "                f.write(response.content)\n",
        "            print(f\"Downloaded: {filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to download {image_url}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dask.distributed import Client\n",
        "client = Client(threads_per_worker=os.cpu_count() // 2, n_workers=os.cpu_count())\n",
        "gadgets = [\"smartphone\", \"tablet\", \"smartwatch\", \"headphones\", \"camera\"]\n",
        "parallel_results = []\n",
        "for gadget in gadgets:\n",
        "    parallel_result= dask.delayed(download_images)(gadget, output_dir=DATASET_DIR / gadget, max_results=200)\n",
        "    parallel_results.append(parallel_result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parallel_results = dask.compute(*parallel_results)\n",
        "print(\"All downloads completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Invalid image: /Users/priyanshuagarwal/Work/my-projects/ml-learning/gadget-predictor/datasets/tablet/tablet_142.jpg - cannot identify image file '/Users/priyanshuagarwal/Work/my-projects/ml-learning/gadget-predictor/datasets/tablet/tablet_142.jpg'\n",
            "Invalid image: /Users/priyanshuagarwal/Work/my-projects/ml-learning/gadget-predictor/datasets/smartwatch/smartwatch_57.jpg - cannot identify image file '/Users/priyanshuagarwal/Work/my-projects/ml-learning/gadget-predictor/datasets/smartwatch/smartwatch_57.jpg'\n",
            "Invalid image: /Users/priyanshuagarwal/Work/my-projects/ml-learning/gadget-predictor/datasets/smartphone/smartphone_150.svg - cannot identify image file '/Users/priyanshuagarwal/Work/my-projects/ml-learning/gadget-predictor/datasets/smartphone/smartphone_150.svg'\n",
            "Invalid image: /Users/priyanshuagarwal/Work/my-projects/ml-learning/gadget-predictor/datasets/camera/camera_75.jpg - cannot identify image file '/Users/priyanshuagarwal/Work/my-projects/ml-learning/gadget-predictor/datasets/camera/camera_75.jpg'\n",
            "Invalid image: /Users/priyanshuagarwal/Work/my-projects/ml-learning/gadget-predictor/datasets/laptop/laptop_157.jpg - cannot identify image file '/Users/priyanshuagarwal/Work/my-projects/ml-learning/gadget-predictor/datasets/laptop/laptop_157.jpg'\n",
            "Number of invalid images: 5\n",
            "Removed invalid image: /Users/priyanshuagarwal/Work/my-projects/ml-learning/gadget-predictor/datasets/tablet/tablet_142.jpg\n",
            "Removed invalid image: /Users/priyanshuagarwal/Work/my-projects/ml-learning/gadget-predictor/datasets/smartwatch/smartwatch_57.jpg\n",
            "Removed invalid image: /Users/priyanshuagarwal/Work/my-projects/ml-learning/gadget-predictor/datasets/smartphone/smartphone_150.svg\n",
            "Removed invalid image: /Users/priyanshuagarwal/Work/my-projects/ml-learning/gadget-predictor/datasets/camera/camera_75.jpg\n",
            "Removed invalid image: /Users/priyanshuagarwal/Work/my-projects/ml-learning/gadget-predictor/datasets/laptop/laptop_157.jpg\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def validate_images(directory):\n",
        "  invalid_images = []\n",
        "  for root, _, files in os.walk(directory):\n",
        "    for file in files:\n",
        "      file_path = os.path.join(root, file)\n",
        "      try:\n",
        "        with Image.open(file_path) as img:\n",
        "          img.verify()  # Verify if the file is a valid image\n",
        "      except Exception as e:\n",
        "        invalid_images.append(file_path)\n",
        "        print(f\"Invalid image: {file_path} - {e}\")\n",
        "  return invalid_images\n",
        "\n",
        "invalid_files = validate_images(DATASET_DIR)\n",
        "print(f\"Number of invalid images: {len(invalid_files)}\")\n",
        "\n",
        "# Remove invalid images\n",
        "for invalid_file in invalid_files:\n",
        "    try:\n",
        "        os.remove(invalid_file)\n",
        "        print(f\"Removed invalid image: {invalid_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to remove {invalid_file}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Load dataset\n",
        "dataset = datasets.ImageFolder(DATASET_DIR, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3: Use pre-trained ResNet\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, len(dataset.classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Train\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Loss: 0.6606, Accuracy: 76.94%\n",
            "Epoch 2 - Loss: 0.4397, Accuracy: 83.87%\n",
            "Epoch 3 - Loss: 0.3399, Accuracy: 88.24%\n",
            "Epoch 4 - Loss: 0.2457, Accuracy: 90.80%\n",
            "Epoch 5 - Loss: 0.1763, Accuracy: 94.78%\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(5):  # Train for 5 epochs\n",
        "    model.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Accuracy Calculation\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "    print(f\"Epoch {epoch+1} - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "virtual-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
