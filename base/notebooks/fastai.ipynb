{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "project_root = Path.cwd().resolve().parents[0]\n",
    "print(project_root)\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from pathlib import Path\n",
    "from src.shared.constants import DATASET_DIR\n",
    "from src.shared.tiler import Tiler, BatchConfig\n",
    "import numpy as np\n",
    "import gc\n",
    "from fastai.data.block import DataBlock\n",
    "from fastai.data.transforms import RandomSplitter\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import EarlyStoppingCallback\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MemoryEfficientTilerDataset:\n",
    "    \"\"\"Memory-optimized dataset - NO CACHING.\"\"\"\n",
    "    def __init__(self, image_tiler: Tiler, label_tiler: Tiler = None, min_building_ratio: float = 0.1):\n",
    "        self.image_tiler = image_tiler\n",
    "        self.label_tiler = label_tiler\n",
    "\n",
    "        if label_tiler and min_building_ratio > 0:\n",
    "            self.valid_indices = self._filter_tiles_by_content_efficient(min_building_ratio)\n",
    "        else:\n",
    "            self.valid_indices = list(range(len(image_tiler)))\n",
    "\n",
    "        print(f\"Memory-Efficient Tiler Dataset: {len(self.valid_indices)} valid tiles\")\n",
    "\n",
    "    def _filter_tiles_by_content_efficient(self, min_building_ratio):\n",
    "        valid_indices = []\n",
    "\n",
    "        for idx in range(len(self.image_tiler)):  # Check **all** tiles\n",
    "            try:\n",
    "                label_tile = self.label_tiler.get_tile_by_id(idx, as_numpy=True)  # shape: C,H,W or H,W\n",
    "                building_ratio = np.mean(label_tile == 1)\n",
    "\n",
    "                if building_ratio >= min_building_ratio:\n",
    "                    valid_indices.append(idx)  # Keep only this tile\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not check tile {idx}: {e}\")\n",
    "                continue\n",
    "\n",
    "        return valid_indices  # No set/sorting needed\n",
    "\n",
    "    def __len__(self): return len(self.valid_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        actual_idx = self.valid_indices[idx]\n",
    "\n",
    "        # ----- IMAGE: C,H,W, uint8 -----\n",
    "        image_np = self.image_tiler.get_tile_by_id(actual_idx, as_numpy=True)  # (C,H,W)\n",
    "        \n",
    "        # Ensure image is at least 3 channels\n",
    "        if image_np.ndim == 2:\n",
    "            image_np = np.repeat(image_np[None, ...], 3, axis=0)  # (3,H,W)\n",
    "        elif image_np.shape[0] >= 4:\n",
    "            image_np = image_np[:3]  # Trim to RGB\n",
    "\n",
    "        img_t = torch.from_numpy(image_np.copy())      # uint8, (3,H,W)\n",
    "        img_t = TensorImage(img_t)                     # fastai wrapper\n",
    "\n",
    "        # ----- MASK: H,W, long -----\n",
    "        label_np = self.label_tiler.get_tile_by_id(actual_idx, as_numpy=True)  # (C,H,W) or (H,W)\n",
    "        if label_np.ndim == 3:\n",
    "            label_np = label_np[0] if label_np.shape[0] > 1 else np.squeeze(label_np, axis=0)\n",
    "        mask_np = (label_np == 1).astype(np.uint8)      # binary mask (0 or 1)\n",
    "        mask_t = torch.from_numpy(mask_np.copy()).long()\n",
    "        mask_t = TensorMask(mask_t)\n",
    "\n",
    "        return (img_t, mask_t)\n",
    "    \n",
    "def create_memory_efficient_tiler_dls(\n",
    "    image_path: str,\n",
    "    label_path: str = None,\n",
    "    tile_size: int = 256,\n",
    "    overlap: int = 32,\n",
    "    batch_size: int = 2,\n",
    "    valid_pct: float = 0.2,\n",
    "    min_building_ratio: float = 0.1,\n",
    "    **kwargs\n",
    "):\n",
    "    # MEMORY-OPTIMIZED CONFIG\n",
    "    config = BatchConfig(\n",
    "        batch_size=8,\n",
    "        prefetch_batches=2,\n",
    "        max_workers=4,\n",
    "        enable_cache=False,\n",
    "        memory_limit_mb=2048\n",
    "    )\n",
    "\n",
    "    image_tiler = Tiler(image_path, tile_size=tile_size, overlap=overlap, batch_config=config)\n",
    "    label_tiler = Tiler(label_path, tile_size=tile_size, overlap=overlap, batch_config=config) if label_path else None\n",
    "\n",
    "    dataset = MemoryEfficientTilerDataset(\n",
    "        image_tiler=image_tiler,\n",
    "        label_tiler=label_tiler,\n",
    "        min_building_ratio=min_building_ratio\n",
    "    )\n",
    "\n",
    "    def get_items(_): return list(range(len(dataset)))\n",
    "\n",
    "    def get_x(i):\n",
    "        itm = dataset[i]\n",
    "        return itm[0] if isinstance(itm, tuple) else itm\n",
    "\n",
    "    tile_size = 1024  # your current tiles\n",
    "\n",
    "    # xtra transforms:\n",
    "    xtra = [\n",
    "        Dihedral(p=0.7),                 # 8-way: flips + 90Â° rotations (orthos love this)\n",
    "        Rotate(max_deg=10, p=0.5),       # small free-angle rotation\n",
    "        Zoom(min_zoom=1.0, max_zoom=1.20, p=0.7),  # small scale jitter\n",
    "        # optional: light blur/noise for robustness\n",
    "        RandomErasing(p=0.05, max_count=1),        # tiny occlusions (acts like mild Cutout)\n",
    "    ]\n",
    "\n",
    "    batch_tfms = [\n",
    "        *aug_transforms(                  # uses affine + lighting together\n",
    "            do_flip=True, flip_vert=True,\n",
    "            max_rotate=0,                 # (we add Rotate separately to keep control)\n",
    "            min_zoom=1.0, max_zoom=1.0,   # (zoom handled by Zoom() above)\n",
    "            max_lighting=0.25, p_lighting=0.9,\n",
    "            max_warp=0.0,                 # no perspective/elastic twists\n",
    "        ),\n",
    "        Normalize.from_stats(*imagenet_stats),\n",
    "        # Optional: tiny noise/blurâ€”uncomment if needed\n",
    "        # GAussianBlur(p=0.15, sigma=(0.1, 1.0)),   # requires torchvision>=0.13 transforms\n",
    "    ]\n",
    "\n",
    "    def ImgTBlock():\n",
    "        return TransformBlock()\n",
    "\n",
    "    def MaskTBlock(codes):\n",
    "        return TransformBlock(item_tfms=AddMaskCodes(codes=codes))\n",
    "\n",
    "    if label_path:\n",
    "        def get_y(i):\n",
    "            _, m = dataset[i]\n",
    "            return m\n",
    "\n",
    "        dblock = DataBlock(\n",
    "            blocks=(ImgTBlock, MaskTBlock(codes=['background', 'building'])),\n",
    "            get_items=get_items,\n",
    "            get_x=get_x,\n",
    "            get_y=get_y,\n",
    "            splitter=RandomSplitter(valid_pct=valid_pct, seed=42),\n",
    "            item_tfms=[],\n",
    "            batch_tfms=[IntToFloatTensor(), *xtra, *batch_tfms]\n",
    "        )\n",
    "    else:\n",
    "        dblock = DataBlock(\n",
    "            blocks=(ImgTBlock,),\n",
    "            get_items=get_items,\n",
    "            get_x=get_x,\n",
    "            splitter=RandomSplitter(valid_pct=valid_pct, seed=42),\n",
    "            batch_tfms=[IntToFloatTensor(), Normalize.from_stats(*imagenet_stats)]\n",
    "        )\n",
    "\n",
    "    # IMPORTANT: don't pass path=None; use '.' or omit entirely. Also use num_workers=0.\n",
    "    return dblock.dataloaders(\n",
    "        source=None,\n",
    "        bs=batch_size,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "        # path='.'   # optional; or just omit the path argument\n",
    "        **kwargs\n",
    "    )\n",
    "# Memory monitoring utility\n",
    "def monitor_memory():\n",
    "    import psutil\n",
    "    process = psutil.Process()\n",
    "    memory_mb = process.memory_info().rss / 1024 / 1024\n",
    "    print(f\"Current memory usage: {memory_mb:.1f} MB\")\n",
    "    return memory_mb\n",
    "\n",
    "def train_with_memory_monitoring(image_path: str, label_path: str, arch=resnet34, **kwargs):\n",
    "    print(\"ðŸ§  Initial memory usage:\")\n",
    "    monitor_memory()\n",
    "    dls = create_memory_efficient_tiler_dls(\n",
    "        image_path=image_path,\n",
    "        label_path=label_path,\n",
    "        **kwargs\n",
    "    )\n",
    "    print(\"ðŸ§  After creating DataLoaders:\")\n",
    "    monitor_memory()\n",
    "    print(f\"ðŸŽ¯ Created DataLoaders with {len(dls.train)} batches\")\n",
    "\n",
    "    learn = unet_learner(\n",
    "        dls,\n",
    "        arch,\n",
    "        metrics=[DiceMulti()],\n",
    "        loss_func=CrossEntropyLossFlat(axis=1),\n",
    "        cbs=[EarlyStoppingCallback(patience=3)],\n",
    "        pretrained=True\n",
    "    )\n",
    "    dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    learn.model.to(dev)\n",
    "\n",
    "    print(\"ðŸ§  After creating learner:\")\n",
    "    monitor_memory()\n",
    "    return learn, dls\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ðŸ§  Starting memory usage:\")\n",
    "    monitor_memory()\n",
    "\n",
    "    learn, dls = train_with_memory_monitoring(\n",
    "        image_path=Path(DATASET_DIR / \"ortho_cog_cropped.tif\"),\n",
    "        label_path=Path(DATASET_DIR / \"building_mask.tif\"),\n",
    "        tile_size=1024,\n",
    "        overlap=256,\n",
    "        batch_size=4,\n",
    "    )\n",
    "\n",
    "    print(\"ðŸ§  Final memory usage:\")\n",
    "    monitor_memory()\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xb, yb = dls.one_batch()\n",
    "dls.show_batch(max_n=10, figsize=(10,10))\n",
    "learn.model.eval()\n",
    "# with torch.inference_mode():\n",
    "#   logits = learn.model(xb)            # [B, C, H, W]\n",
    "#   pred = logits.argmax(dim=1)         # [B, H, W]  (0=background, 1=building)\n",
    "\n",
    "interp = SegmentationInterpretation.from_learner(learn)\n",
    "interp.show_results(k=3)\n",
    "# print(\"xb:\", xb.shape, \"yb:\", yb.shape, \"pred:\", pred.shape)\n",
    "\n",
    "# # visualize a couple of samples\n",
    "# import matplotlib.pyplot as plt\n",
    "# for i in range(min(3, xb.shape[0])):\n",
    "#   img = xb[i].cpu().permute(1,2,0).clamp(0,1).numpy()\n",
    "#   gt  = yb[i].cpu().numpy()\n",
    "#   pr  = pred[i].cpu().numpy()\n",
    "#   fig, axs = plt.subplots(1,3, figsize=(10,3))\n",
    "#   axs[0].imshow(img); axs[0].set_title(\"Image\"); axs[0].axis('off')\n",
    "#   axs[1].imshow(gt, vmin=0, vmax=1); axs[1].set_title(\"GT\"); axs[1].axis('off')\n",
    "#   axs[2].imshow(pr, vmin=0, vmax=1); axs[2].set_title(\"Pred\"); axs[2].axis('off')\n",
    "#   plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "# cmap = ListedColormap([\n",
    "#     (0.0, 0.0, 0.0, 1.0),   # black background\n",
    "#     (0.0, 0.8, 0.2, 0.9),   # bright green buildings\n",
    "# ])\n",
    "# interp.show_results(idxs=[1,2,3], cmap=cmap, alpha=0.6, vmin=0, vmax=1)\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
