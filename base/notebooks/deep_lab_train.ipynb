{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Project Root Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "project_root = Path.cwd().resolve().parents[0]\n",
    "print(project_root)\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models_pytorch import DeepLabV3Plus\n",
    "from src.shared.constants import IMAGENET_MEAN, IMAGENET_STD\n",
    "from src.data.datasets.ortho_dataset import MultiRasterPairTileDataset\n",
    "from src.models.schedulers import cosine_with_warmup\n",
    "from src.models.losses import bce_loss\n",
    "from src.models.optimizers import make_optimizer\n",
    "from src.models.training_utils import EMA\n",
    "from src.models.trainers import DeepLabV3Trainer\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import os\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Configuration Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs.\n",
    "val_split = 0.1\n",
    "num_workers = 4\n",
    "batch_size = 4\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "epochs = 30\n",
    "threshold = 0.65  # Increased threshold for crisper building boundaries\n",
    "lr = 2.5e-4  # Scaled for batch_size=4\n",
    "shutdown_after_training = True  # Auto-shutdown PC after training completes\n",
    "shutdown_delay = 30  # Delay in seconds before shutdown (gives time to cancel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Dataset and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare Dataset.\n",
    "ortho_mask_pairs = [\n",
    "    (\n",
    "        \"../../SSRS/data/MOPR/ortho_cog_cropped.tif\",\n",
    "        \"../../SSRS/data/MOPR/building_mask.tif\",\n",
    "    ),\n",
    "    (\n",
    "        \"../../SSRS/data/Aarvi/ortho.tif\",\n",
    "        \"../../SSRS/data/Aarvi/building_mask.tif\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "dataset = MultiRasterPairTileDataset(\n",
    "    ortho_mask_pairs=ortho_mask_pairs,\n",
    "    tile_size=1024,\n",
    "    overlap=512,\n",
    "    mean=IMAGENET_MEAN,\n",
    "    std=IMAGENET_STD,\n",
    "    reject_empty=True,\n",
    "    train_scales=(1, 2, 4),\n",
    "    augment=True,\n",
    "    augment_prob=0.5,\n",
    "    min_building_ratio=0.05\n",
    ")\n",
    "\n",
    "# # Prepare Loaders.\n",
    "n_total = len(dataset)\n",
    "n_val = max(1, int(val_split * n_total))\n",
    "n_train = n_total - n_val\n",
    "train_ds, val_ds = random_split(\n",
    "    dataset, [n_train, n_val], generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "persistent_workers = num_workers > 0\n",
    "prefetch_factor = 2 if num_workers > 0 else None\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=persistent_workers,\n",
    "    prefetch_factor=prefetch_factor,\n",
    "    collate_fn=dataset.collate_pairs,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=persistent_workers,\n",
    "    prefetch_factor=prefetch_factor,\n",
    "    collate_fn=dataset.collate_pairs,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Model Training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model Training.\n",
    "model = (\n",
    "    DeepLabV3Plus(\n",
    "        encoder_name=\"resnet50\",\n",
    "        encoder_weights=\"imagenet\",\n",
    "        in_channels=3,\n",
    "        classes=1,\n",
    "        loss_function=bce_loss,\n",
    "    )\n",
    "    .to(device)\n",
    "    .to(memory_format=torch.channels_last)\n",
    ")\n",
    "\n",
    "optimizer = make_optimizer(\n",
    "    lr=lr, model=model, weight_decay=1, backbone_lr_mult=0.5\n",
    ")\n",
    "\n",
    "total_steps = max(1, epochs * len(train_loader))\n",
    "\n",
    "scheduler = LambdaLR(\n",
    "    optimizer,\n",
    "    cosine_with_warmup(total_steps, warmup_steps=min(1000, total_steps // 10)),\n",
    ")\n",
    "\n",
    "ema = EMA(model, decay=0.999)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DeepLabV3Trainer(\n",
    "    model=model,\n",
    "    batch_size=batch_size,\n",
    "    loss_function=bce_loss,\n",
    "    device=device,\n",
    "    ema=ema,\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Start training\n",
    "    trainer.train(train_loader=train_loader, val_loader=val_loader, epochs=epochs, scheduler=scheduler, optimizer=optimizer)\n",
    "    \n",
    "    # Training completed successfully\n",
    "    print(\"\\n‚úÖ Training completed successfully!\")\n",
    "    \n",
    "    # Optional: Auto-shutdown after training\n",
    "    if shutdown_after_training:\n",
    "        print(f\"\\nüîå System will shutdown in {shutdown_delay} seconds...\")\n",
    "        print(\"üí° Press Ctrl+C to cancel shutdown\")\n",
    "        \n",
    "        try:\n",
    "            # Countdown with option to cancel\n",
    "            for i in range(shutdown_delay, 0, -1):\n",
    "                print(f\"‚è∞ Shutting down in {i:2d} seconds...\", end='\\r')\n",
    "                time.sleep(1)\n",
    "            \n",
    "            print(\"\\nüõë Shutting down now...\")\n",
    "            # Execute shutdown command for Linux\n",
    "            os.system('sudo shutdown -h now')\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n‚ùå Shutdown cancelled by user\")\n",
    "            print(\"‚úÖ Training results saved. System will remain on.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Training failed with error: {e}\")\n",
    "    print(\"üö´ Auto-shutdown cancelled due to training failure\")\n",
    "    raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Prediction Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load_checkpoint(\"./checkpoints/deeplabv3p_best_overviews.pt\")\n",
    "trainer.predict(\n",
    "    \"../../SSRS/data/Shahada/ortho.tif\",\n",
    "    out_dir=\"predictions\",\n",
    "    num_workers=8,\n",
    "    predict_scales=(1, 2),  # Multi-scale for better quality\n",
    "    blocksize=256,  # Smaller blocks for better I/O\n",
    "    threshold=threshold,\n",
    "    batch_size=8,   \n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
